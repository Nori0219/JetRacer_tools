{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uO3gE2d5KLPb"
   },
   "source": [
    "# JetRacer Cloud Trainer \n",
    "\n",
    "このノートブックは、Google ColabのGPUを利用してJetRacerのAIモデルを学習するためのツールです。\n",
    "\n",
    "**主な機能:**\n",
    "- **インタラクティブUI:** ボタンやスライダーで直感的に操作できます。学習率（Learning Rate）の変更も行えます\n",
    "- **ダイレクトアップロード:** Google Driveを経由せず、直接データセット（zipファイル）をアップロードできます。\n",
    "- **学習結果のCSV出力:** 学習の進捗をCSVファイルに保存し、後からグラフ化や分析が可能です。\n",
    "- **リアルタイム進捗表示:** 学習状況や動画の作成状況をリアルタイムで確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-f2i_hNKLPd"
   },
   "source": [
    "### **ステップ0: 必要なパッケージのインストール**\n",
    "\n",
    "最初に、モデルの学習に必要なPythonスクリプトをダウンロードします。\n",
    "（カスタムしている場合は、直接2つのファイルをuploadしてください）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_bSn9y3KLPd"
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/NVIDIA-AI-IOT/jetracer/master/notebooks/utils.py\n",
    "!wget -q https://raw.githubusercontent.com/NVIDIA-AI-IOT/jetracer/master/notebooks/xy_dataset.py\n",
    "print(\"✅ 準備が完了しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kE1U61FKLPe"
   },
   "source": [
    "### **ステップ1: データセットの準備**\n",
    "\n",
    "下の「Upload Datasets (.zip)」ボタンを使い、JetRacerで収集したデータセットのzipファイルをアップロードしてください。複数ファイルの同時アップロードも可能です。\n",
    "\n",
    "アップロードが完了すると、ファイルが自動的に展開され、下のドロップダウンメニューに追加されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jS1pD-q1KLPe"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# --- UIウィジェット ---\n",
    "upload_button = widgets.Button(\n",
    "    description='Upload Datasets (.zip)',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to upload zip files containing datasets',\n",
    "    icon='upload'\n",
    ")\n",
    "upload_output = widgets.Output() # ログや処理状況を表示するエリア\n",
    "dataset_list_widget = widgets.SelectMultiple(\n",
    "    options=[],\n",
    "    description='学習に使用するデータセット:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='100%', height='150px')\n",
    ")\n",
    "\n",
    "# --- 関数 ---\n",
    "def find_xy_path(root_dir):\n",
    "    \"\"\"指定されたディレクトリ内を再帰的に検索し、'xy'フォルダを含むディレクトリのパスを返す\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        if 'xy' in dirnames:\n",
    "            return dirpath\n",
    "    return None\n",
    "\n",
    "def on_upload_button_clicked(b):\n",
    "    with upload_output:\n",
    "        clear_output() # 以前のログをクリア\n",
    "        print(\"ファイル選択ダイアログを開きます。アップロードするzipファイルを選択してください。\")\n",
    "        \n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if not uploaded:\n",
    "            print(\"ファイルがアップロードされませんでした。\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nアップロード処理中...\")\n",
    "        \n",
    "        current_options = list(dataset_list_widget.options)\n",
    "        \n",
    "        for name, content in uploaded.items():\n",
    "            try:\n",
    "                with zipfile.ZipFile(io.BytesIO(content), 'r') as zf:\n",
    "                    extract_base_path = os.path.join('/content/', os.path.splitext(name)[0])\n",
    "                    if os.path.exists(extract_base_path):\n",
    "                        shutil.rmtree(extract_base_path) # 古いディレクトリを削除\n",
    "                    os.makedirs(extract_base_path)\n",
    "                    \n",
    "                    zf.extractall(extract_base_path)\n",
    "                    \n",
    "                    # 展開されたディレクトリ内で'xy'フォルダを持つパスを探索\n",
    "                    final_path = find_xy_path(extract_base_path)\n",
    "\n",
    "                    if final_path and final_path not in current_options:\n",
    "                        current_options.append(final_path)\n",
    "                        print(f\"✅ '{name}' を展開し、データセットパス '{final_path}' を検出しました。\")\n",
    "                    elif final_path:\n",
    "                         print(f\"ℹ️ '{name}' は既に追加されています。\")\n",
    "                    else:\n",
    "                        print(f\"❌ '{name}' を展開しましたが、'xy'ディレクトリが見つかりませんでした。zipの構造を確認してください。\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ '{name}' の処理中にエラーが発生しました: {e}\")\n",
    "        \n",
    "        dataset_list_widget.options = sorted(current_options)\n",
    "        dataset_list_widget.value = tuple(sorted(current_options))\n",
    "        print(\"\\nデータセットリストを更新しました。\")\n",
    "\n",
    "upload_button.on_click(on_upload_button_clicked)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([upload_button]), \n",
    "    upload_output, \n",
    "    dataset_list_widget\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_o8b84dKLPh"
   },
   "source": [
    "### **ステップ2: モデルの学習**\n",
    "\n",
    "上のリストから学習に使用したいデータセットを選択し、エポック数とバッチサイズを設定して「学習開始」ボタンを押してください。\n",
    "- **Epochs:** データセット全体を何回繰り返し学習するか。\n",
    "- **Batch Size:** 一度に何枚の画像をまとめて処理するか。\n",
    "\n",
    "学習が完了すると、最も性能の良かったモデル `cloud_best_model.pth` と、学習記録 `learning_log.csv` が生成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-1jA8jVKLPh"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import ConcatDataset, DataLoader, random_split, Subset\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from xy_dataset import XYDataset\n",
    "\n",
    "# --- モデル定義と学習関数 ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = None\n",
    "optimizer = None\n",
    "output_dim = 4 # xy and speed (2*2)\n",
    "\n",
    "def get_model(model_path=None):\n",
    "    global output_dim\n",
    "    weights = 'DEFAULT' if not model_path else None\n",
    "    current_model = torchvision.models.resnet18(weights=weights)\n",
    "    current_model.fc = torch.nn.Linear(512, output_dim)\n",
    "    if model_path and os.path.exists(model_path):\n",
    "        print(f\"'{model_path}' から学習済みの重みを読み込みます...\")\n",
    "        current_model.load_state_dict(torch.load(model_path))\n",
    "    else:\n",
    "        print(\"ResNet-18の学習済みモデルから新規に学習を開始します...\")\n",
    "    return current_model.to(device)\n",
    "\n",
    "def train_model(b):\n",
    "    global model, optimizer\n",
    "    train_button.disabled = True\n",
    "    train_log_widget.value = \"学習準備中...\\n\"\n",
    "    with graph_output_live:\n",
    "        clear_output()\n",
    "\n",
    "    # データセットの準備\n",
    "    selected_datasets = dataset_list_widget.value\n",
    "    if not selected_datasets:\n",
    "        train_log_widget.value = \"エラー: 学習するデータセットが選択されていません。\"\n",
    "        train_button.disabled = False\n",
    "        return\n",
    "        \n",
    "    all_datasets = []\n",
    "    train_log_widget.value += \"データセットを読み込んでいます...\\n\"\n",
    "    for path in selected_datasets:\n",
    "        try:\n",
    "            dataset = XYDataset(path, ['xy', 'speed'], \n",
    "                transforms.Compose([\n",
    "                    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2), #(brightness=0.5, contrast=0.2, saturation=0.2, hue=0.2)これだと輝度のばらつきが改善するかも\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ]), random_hflip=True)\n",
    "            all_datasets.append(dataset)\n",
    "            train_log_widget.value += f\"- '{path}' ({len(dataset)}件) 読み込み完了\\n\"\n",
    "        except Exception as e:\n",
    "             train_log_widget.value += f\"- 警告: '{path}' の読み込み失敗: {e}\\n\"\n",
    "    \n",
    "    if not all_datasets:\n",
    "        train_log_widget.value += \"\\nエラー: 有効なデータセットがありません。\"\n",
    "        train_button.disabled = False\n",
    "        return\n",
    "\n",
    "    full_dataset = ConcatDataset(all_datasets)\n",
    "    \n",
    "    # データの分割\n",
    "    test_split = 0.1\n",
    "    test_size = int(len(full_dataset) * test_split)\n",
    "    train_size = len(full_dataset) - test_size\n",
    "    train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_widget.value, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_widget.value, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # モデルとオプティマイザの初期化\n",
    "    model = get_model()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    epochs = epochs_widget.value\n",
    "    log_data = []\n",
    "\n",
    "    train_log_widget.value = f\"学習を開始します (Total: {len(full_dataset)}, Train: {train_size}, Test: {test_size})\\n\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for images, category_idx, xy in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
    "            images, xy = images.to(device), xy.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = 0.0\n",
    "            for i, cat_idx in enumerate(category_idx.flatten()):\n",
    "                loss += torch.mean((outputs[i][2*cat_idx:2*cat_idx+2] - xy[i])**2)\n",
    "            loss /= len(category_idx)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, category_idx, xy in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs} [Test]\"):\n",
    "                images, xy = images.to(device), xy.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = 0.0\n",
    "                for i, cat_idx in enumerate(category_idx.flatten()):\n",
    "                    loss += torch.mean((outputs[i][2*cat_idx:2*cat_idx+2] - xy[i])**2)\n",
    "                loss /= len(category_idx)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        \n",
    "        log_data.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'test_loss': avg_test_loss\n",
    "        })\n",
    "        \n",
    "        train_log_widget.value += f\"Epoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.5f}, Test Loss: {avg_test_loss:.5f}\\n\"\n",
    "        train_progress_widget.value = (epoch + 1) / epochs\n",
    "        \n",
    "        if avg_test_loss < best_loss:\n",
    "            best_loss = avg_test_loss\n",
    "            torch.save(model.state_dict(), 'cloud_best_model.pth')\n",
    "            train_log_widget.value += f\"  -> ✨ New best model saved with loss: {best_loss:.5f}\\n\"\n",
    "        \n",
    "        # 各エポック終了時にグラフを更新\n",
    "        with graph_output_live:\n",
    "            clear_output(wait=True)\n",
    "            df_live = pd.DataFrame(log_data)\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(df_live['epoch'], df_live['train_loss'], 'o-', label='Train Loss')\n",
    "            plt.plot(df_live['epoch'], df_live['test_loss'], 'o-', label='Test Loss')\n",
    "            plt.title(f\"Learning Curve (Train: {train_size} / Test: {test_size})\")\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    # CSVログの保存\n",
    "    df = pd.DataFrame(log_data)\n",
    "    df.to_csv('learning_log.csv', index=False)\n",
    "    \n",
    "    train_log_widget.value += \"\\n✅ 学習が完了しました。\\n\"\n",
    "    train_log_widget.value += \"'cloud_best_model.pth' と 'learning_log.csv' が保存されました。\\n\"\n",
    "    train_button.disabled = False\n",
    "    download_button.disabled = False\n",
    "    csv_download_button.disabled = False\n",
    "\n",
    "# --- UIウィジェット (学習) ---\n",
    "epochs_widget = widgets.IntText(description='Epochs', value=30, layout=widgets.Layout(width='150px'))\n",
    "batch_widget = widgets.IntText(description='Batch Size', value=8, layout=widgets.Layout(width='150px'))\n",
    "train_button = widgets.Button(description='学習開始', button_style='success')\n",
    "train_progress_widget = widgets.FloatProgress(min=0.0, max=1.0, description='Progress')\n",
    "train_log_widget = widgets.Textarea(layout=widgets.Layout(width='100%', height='250px'))\n",
    "graph_output_live = widgets.Output() # リアルタイムグラフ表示用\n",
    "\n",
    "# --- イベントリスナー (学習) ---\n",
    "train_button.on_click(train_model)\n",
    "\n",
    "# --- UI表示 (学習) ---\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([epochs_widget, batch_widget]), \n",
    "    train_button, \n",
    "    train_progress_widget, \n",
    "    train_log_widget,\n",
    "    graph_output_live\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eL3Ym5T-KLPj"
   },
   "source": [
    "### **ステップ3: 学習結果のダウンロード**\n",
    "\n",
    "学習で生成されたベストモデルと学習ログ（CSV）をダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7M9H9pUKLPk"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description=\"Download Model (.pth)\", \n",
    "    button_style='info',\n",
    "    disabled=True\n",
    ")\n",
    "csv_download_button = widgets.Button(\n",
    "    description=\"Download Log (.csv)\", \n",
    "    button_style='info',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "def download_model(b):\n",
    "    if os.path.exists('cloud_best_model.pth'):\n",
    "        files.download('cloud_best_model.pth')\n",
    "    else:\n",
    "        print(\"モデルファイルが見つかりません。\")\n",
    "\n",
    "def download_csv(b):\n",
    "    if os.path.exists('learning_log.csv'):\n",
    "        files.download('learning_log.csv')\n",
    "    else:\n",
    "        print(\"CSVログファイルが見つかりません。\")\n",
    "\n",
    "download_button.on_click(download_model)\n",
    "csv_download_button.on_click(download_csv)\n",
    "\n",
    "display(widgets.HBox([download_button, csv_download_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "new_markdown_cell_for_graph"
   },
   "source": [
    "### **ステップ3.5: 学習曲線の可視化**\n",
    "\n",
    "ステップ2で保存された`learning_log.csv`ファイルを元に、学習の進捗をグラフで表示します。\n",
    "「グラフを表示」ボタンを押してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "new_code_cell_for_graph"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# --- UIウィジェット ---\n",
    "show_graph_button = widgets.Button(\n",
    "    description=\"学習グラフを表示\",\n",
    "    button_style='success'\n",
    ")\n",
    "graph_output = widgets.Output() # グラフ描画用の出力エリア\n",
    "\n",
    "# --- 関数 ---\n",
    "def show_learning_curve(b):\n",
    "    with graph_output:\n",
    "        clear_output(wait=True)\n",
    "        log_file = 'learning_log.csv'\n",
    "        if not os.path.exists(log_file):\n",
    "            print(f\"エラー: {log_file} が見つかりません。先にステップ2の学習を実行してください。\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # CSVファイルを読み込む\n",
    "            df = pd.read_csv(log_file)\n",
    "            \n",
    "            # グラフの描画\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            \n",
    "            ax.plot(df['epoch'], df['train_loss'], marker='o', linestyle='-', label='Train Loss')\n",
    "            ax.plot(df['epoch'], df['test_loss'], marker='o', linestyle='-', label='Test Loss')\n",
    "            \n",
    "            ax.set_title('Learning Curve', fontsize=16)\n",
    "            ax.set_xlabel('Epoch', fontsize=12)\n",
    "            ax.set_ylabel('Loss', fontsize=12)\n",
    "            ax.legend(fontsize=12)\n",
    "            ax.set_xticks(df['epoch'][::max(1, len(df)//10)]) # X軸の目盛りを間引いて表示\n",
    "            \n",
    "            # Test Lossが最小のポイントをマーク\n",
    "            min_test_loss_epoch = df.loc[df['test_loss'].idxmin()]\n",
    "            ax.annotate(f\"Best Model\\nEpoch: {int(min_test_loss_epoch['epoch'])}\\nLoss: {min_test_loss_epoch['test_loss']:.4f}\",\n",
    "                        xy=(min_test_loss_epoch['epoch'], min_test_loss_epoch['test_loss']),\n",
    "                        xytext=(min_test_loss_epoch['epoch'], min_test_loss_epoch['test_loss'] + 0.02),\n",
    "                        arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", ec=\"black\", lw=1, alpha=0.7))\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"グラフの描画中にエラーが発生しました: {e}\")\n",
    "\n",
    "# --- イベントリスナー ---\n",
    "show_graph_button.on_click(show_learning_curve)\n",
    "\n",
    "# --- UI表示 ---\n",
    "display(widgets.VBox([show_graph_button, graph_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oY2s_T48KLPk"
   },
   "source": [
    "### **ステップ4: 評価動画の作成**\n",
    "\n",
    "学習したモデルの性能を視覚的に確認するための動画を作成します。\n",
    "まず、評価に使用するデータセット（学習に使っていないデータが望ましい）をアップロードしてください。その後、ドロップダウンからデータセットを選択し、「動画を作成」ボタンを押します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7tB5d7nKLPl"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from utils import preprocess\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "from google.colab import files\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import zipfile\n",
    "import io\n",
    "import shutil\n",
    "\n",
    "# --- グローバル変数 ---\n",
    "generated_video_path = None\n",
    "\n",
    "# --- UIウィジェット (評価) ---\n",
    "eval_upload_button = widgets.Button(\n",
    "    description='Upload Eval Data (.zip)',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to upload zip files for evaluation',\n",
    "    icon='upload'\n",
    ")\n",
    "eval_upload_output = widgets.Output()\n",
    "video_dataset_widget = widgets.Dropdown(options=[], description='データセット:')\n",
    "video_name_widget = widgets.Text(description='動画ファイル名:', value='evaluation_video.mp4')\n",
    "create_video_button = widgets.Button(description='動画を作成', button_style='success')\n",
    "video_log_widget = widgets.Textarea(layout=widgets.Layout(width='100%', height='150px'))\n",
    "video_player_widget = widgets.Output()\n",
    "video_download_button = widgets.Button(description=\"Download Video (.mp4)\", button_style='info', disabled=True)\n",
    "\n",
    "# --- 関数 (評価) ---\n",
    "def find_xy_path_eval(root_dir):\n",
    "    \"\"\"評価用のxyパス検索関数\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        if 'xy' in dirnames:\n",
    "            return dirpath\n",
    "    return None\n",
    "\n",
    "def on_eval_upload_button_clicked(b):\n",
    "    with eval_upload_output:\n",
    "        clear_output(wait=True)\n",
    "        print(\"評価用のzipファイルを選択してください。\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if not uploaded:\n",
    "            print(\"ファイルがアップロードされませんでした。\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nアップロード処理中...\")\n",
    "        current_options = list(video_dataset_widget.options)\n",
    "        \n",
    "        for name, content in uploaded.items():\n",
    "            try:\n",
    "                with zipfile.ZipFile(io.BytesIO(content), 'r') as zf:\n",
    "                    extract_base_path = os.path.join('/content/eval/', os.path.splitext(name)[0])\n",
    "                    if os.path.exists(extract_base_path):\n",
    "                        shutil.rmtree(extract_base_path)\n",
    "                    os.makedirs(extract_base_path)\n",
    "                    \n",
    "                    zf.extractall(extract_base_path)\n",
    "                    \n",
    "                    final_path = find_xy_path_eval(extract_base_path)\n",
    "\n",
    "                    if final_path and final_path not in current_options:\n",
    "                        current_options.append(final_path)\n",
    "                        print(f\"✅ '{name}' を展開し、データセットパス '{final_path}' を検出しました。\")\n",
    "                    elif final_path:\n",
    "                        print(f\"ℹ️ '{name}' は既に追加されています。\")\n",
    "                    else:\n",
    "                        print(f\"❌ '{name}' を展開しましたが 'xy' ディレクトリが見つかりませんでした。\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ '{name}' の処理中にエラーが発生しました: {e}\")\n",
    "        \n",
    "        video_dataset_widget.options = sorted(current_options)\n",
    "        print(\"\\n評価用データセットのリストを更新しました。\")\n",
    "\n",
    "def create_video(b):\n",
    "    global generated_video_path\n",
    "    create_video_button.disabled = True\n",
    "    video_log_widget.value = \"動画作成を開始します...\\n\"\n",
    "\n",
    "    if not os.path.exists('cloud_best_model.pth'):\n",
    "        video_log_widget.value += \"エラー: モデルファイル 'cloud_best_model.pth' が見つかりません。先に学習を実行してください。\"\n",
    "        create_video_button.disabled = False\n",
    "        return\n",
    "\n",
    "    eval_model = get_model('cloud_best_model.pth')\n",
    "    eval_model.eval()\n",
    "\n",
    "    dataset_path = video_dataset_widget.value\n",
    "    if not dataset_path:\n",
    "        video_log_widget.value += \"エラー: 評価するデータセットを選択してください。\"\n",
    "        create_video_button.disabled = False\n",
    "        return\n",
    "\n",
    "    image_dir = os.path.join(dataset_path, 'xy')\n",
    "    if not os.path.exists(image_dir):\n",
    "        video_log_widget.value += f\"エラー: ディレクトリ '{image_dir}' が見つかりません。\"\n",
    "        create_video_button.disabled = False\n",
    "        return\n",
    "        \n",
    "    image_files = sorted(glob.glob(os.path.join(image_dir, '*.jpg')), key=os.path.getmtime)\n",
    "    if not image_files:\n",
    "        video_log_widget.value += \"エラー: 画像ファイルが見つかりません。\"\n",
    "        create_video_button.disabled = False\n",
    "        return\n",
    "\n",
    "    output_path = os.path.join('/content/', video_name_widget.value)\n",
    "    generated_video_path = output_path\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 30.0, (224, 224))\n",
    "\n",
    "    for i, image_path in enumerate(tqdm(image_files, desc=\"動画作成中\")):\n",
    "        img = cv2.imread(image_path)\n",
    "        img_resized = cv2.resize(img, (224, 224))\n",
    "        with torch.no_grad():\n",
    "            preprocessed_img = preprocess(img_resized).to(device)\n",
    "            output = eval_model(preprocessed_img).detach().cpu().numpy().flatten()\n",
    "        \n",
    "        x = (output[0] / 2.0 + 0.5) * 224\n",
    "        y = (output[1] / 2.0 + 0.5) * 224\n",
    "        cv2.circle(img_resized, (int(x), int(y)), 8, (255, 0, 0), -1)\n",
    "        out.write(img_resized)\n",
    "\n",
    "    out.release()\n",
    "    video_log_widget.value += f\"\\n✅ 動画の作成が完了しました: {output_path}\\n\"\n",
    "    \n",
    "    # 動画プレイヤーの更新\n",
    "    with video_player_widget:\n",
    "        clear_output(wait=True)\n",
    "        mp4 = open(output_path,'rb').read()\n",
    "        data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "        display(HTML(f'<video width=400 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>'))\n",
    "        \n",
    "    create_video_button.disabled = False\n",
    "    video_download_button.disabled = False\n",
    "\n",
    "def download_video(b):\n",
    "    if generated_video_path and os.path.exists(generated_video_path):\n",
    "        files.download(generated_video_path)\n",
    "    else:\n",
    "        print(\"ビデオファイルが見つかりません。\")\n",
    "\n",
    "# --- イベントリスナー (評価) ---\n",
    "eval_upload_button.on_click(on_eval_upload_button_clicked)\n",
    "create_video_button.on_click(create_video)\n",
    "video_download_button.on_click(download_video)\n",
    "\n",
    "# --- UI表示 (評価) ---\n",
    "eval_ui = widgets.VBox([\n",
    "    eval_upload_button,\n",
    "    eval_upload_output,\n",
    "    widgets.HBox([video_dataset_widget, video_name_widget]),\n",
    "    create_video_button,\n",
    "    video_log_widget,\n",
    "    video_player_widget,\n",
    "    video_download_button\n",
    "])\n",
    "display(eval_ui)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
